import time
import platform
from pathlib import Path
from collections import deque

import cv2
import numpy as np
import onnxruntime as ort
import mediapipe as mp

# ê²½ë¡œ ì„¤ì •
ROOT = Path(__file__).resolve().parent.parent  # eca_presenter/
MODEL_PATH = ROOT / "models" / "gesture_eca.onnx"
LABELS_PATH = ROOT / "assets" / "labels.txt"


# í‚¤ ìž…ë ¥ (Win / macOS)

SYSTEM = platform.system()
IS_WIN = SYSTEM == "Windows"
IS_MAC = SYSTEM == "Darwin"

if IS_WIN:
    import keyboard 
elif IS_MAC:
    import pyautogui

def send_key(key: str):
    """í”Œëž«í¼ì— ë§žê²Œ í‚¤ ìž…ë ¥ ì „ì†¡."""
    if IS_WIN:
        try:
            keyboard.send(key)
        except Exception as e:
            print(f"[WARN] keyboard.send ì‹¤íŒ¨: {e}")
    elif IS_MAC:
        try:
            pyautogui.press(key)
        except Exception as e:
            print(f"[WARN] pyautogui.press ì‹¤íŒ¨: {e}")
    else:
        print(f"[INFO] (ì‹œë®¬) í‚¤ ìž…ë ¥: {key}")


# ì„¤ì •ê°’ (í•„ìš” ì‹œ ì—¬ê¸°ë§Œ ì¡°ì •)
INPUT_SIZE = (224, 224)
CONF_THRESH = 0.5           # ì´ ê°’ ì´ìƒì¼ ë•Œë§Œ ìœ íš¨ íŒì •
STABLE_FRAMES = 3            # ë™ì¼ ê²°ê³¼ê°€ Ní”„ë ˆìž„ ì—°ì† ë‚˜ì™€ì•¼ í™•ì •
COOLDOWN_SEC = 0.7            # ê°™ì€ í‚¤ ì—°íƒ€ ë°©ì§€
MAX_NUM_HANDS = 1             # í•œ ì† ê¸°ì¤€
PAD_PX = 24                   # bbox ì£¼ë³€ ì—¬ë°±
DRAW_VIS = True               # ì‹œê°í™” ë°•ìŠ¤/í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°

# ì¹´ë©”ë¼ ì¸ë±ìŠ¤ (Noneì´ë©´ ì‹¤í–‰ ì‹œ ì„ íƒ ëª¨ë“œ)
CAMERA_INDEX = 1         # ì˜ˆ: ë§¥ë¶ ì¹´ë©”ë¼ê°€ 1ë²ˆì´ë©´ 1ë¡œ ê³ ì •í•´ë„ ë¨

# ë¼ë²¨â†’í‚¤ ë§¤í•‘ (labels.txt ë¼ë²¨ê³¼ ì´ë¦„ì„ ë§žì¶°ì£¼ì„¸ìš”!)
LABEL2KEY = {
    # âœ‹ ì†ë°”ë‹¥ (ë¼ë²¨ì€ fist) â†’ ë‹¤ìŒ ìŠ¬ë¼ì´ë“œ
    "fist": "right",

    # ðŸ‘Œ ok ì‚¬ì¸ â†’ ì´ì „ ìŠ¬ë¼ì´ë“œ
    "ok": "left",

    # ðŸ‘‰ ê²€ì§€ ìœ„ë¡œ â†’ ë ˆì´ì € í¬ì¸í„° í† ê¸€ (ì¼œê¸°/ë„ê¸°ìš©)
    "index_up": "command+l",

    # âœŒ Vìž â†’ ë ˆì´ì € í¬ì¸í„° í† ê¸€ (ë„ê¸°/ì¼œê¸° ë™ì¼ í‚¤)
    "v_sign": "esc",
}

# ìœ í‹¸
def load_labels(path: Path):
    with open(path, "r", encoding="utf-8") as f:
        labs = [ln.strip() for ln in f if ln.strip()]
    return labs

def softmax(x: np.ndarray):
    x = x - x.max(axis=-1, keepdims=True)
    e = np.exp(x)
    return e / e.sum(axis=-1, keepdims=True)

def crop_square_with_pad(img, x1, y1, x2, y2, pad=0):
    h, w = img.shape[:2]
    x1 = max(0, x1 - pad); y1 = max(0, y1 - pad)
    x2 = min(w, x2 + pad); y2 = min(h, y2 + pad)
    # ì •ì‚¬ê°í˜• ë§žì¶”ê¸°
    bw, bh = (x2 - x1), (y2 - y1)
    side = max(bw, bh)
    cx = (x1 + x2) // 2
    cy = (y1 + y2) // 2
    sx1 = max(0, cx - side // 2)
    sy1 = max(0, cy - side // 2)
    sx2 = min(w, sx1 + side)
    sy2 = min(h, sy1 + side)
    return img[sy1:sy2, sx1:sx2], (sx1, sy1, sx2, sy2)

def open_camera(index: int):
    """í”Œëž«í¼ë³„ë¡œ ì¹´ë©”ë¼ë¥¼ ì—°ë‹¤."""
    if IS_MAC:
        cap = cv2.VideoCapture(index, cv2.CAP_AVFOUNDATION)
    else:
        cap = cv2.VideoCapture(index)
    return cap

def select_camera(max_index: int = 4) -> cv2.VideoCapture:
    """ì—¬ëŸ¬ ì¹´ë©”ë¼ ì¤‘ì—ì„œ ì‚¬ìš©ìžê°€ ì„ íƒí•˜ë„ë¡ í•¨."""
    print("[INFO] ì¹´ë©”ë¼ ì„ íƒ ëª¨ë“œ: ë§¥ë¶ ì¹´ë©”ë¼ í™”ë©´ì—ì„œ 's'ë¥¼ ëˆŒëŸ¬ ì„ íƒí•˜ì„¸ìš”.")
    chosen_cap = None
    for idx in range(max_index + 1):
        cap = open_camera(idx)
        if not cap.isOpened():
            cap.release()
            continue

        ok, frame = cap.read()
        if not ok:
            cap.release()
            continue

        txt = f"Camera {idx} - 's' ì„ íƒ, ë‹¤ë¥¸ í‚¤: ë‹¤ìŒìœ¼ë¡œ"
        cv2.putText(frame, txt, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        cv2.imshow("Select Camera", frame)
        key = cv2.waitKey(0) & 0xFF
        cv2.destroyWindow("Select Camera")

        if key == ord('s'):
            print(f"[INFO] Camera {idx} ì„ íƒë¨")
            chosen_cap = cap
            break
        else:
            cap.release()

    if chosen_cap is None:
        raise RuntimeError("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´ë©”ë¼ë¥¼ ì„ íƒí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    return chosen_cap

# ONNX ë¡œë“œ
assert MODEL_PATH.exists(), f"ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}"
labels = load_labels(LABELS_PATH)
print(f"[INFO] labels: {labels}")

providers = (
    ["CUDAExecutionProvider", "CPUExecutionProvider"]
    if "CUDAExecutionProvider" in ort.get_available_providers()
    else ["CPUExecutionProvider"]
)
sess = ort.InferenceSession(str(MODEL_PATH), providers=providers)
in_name = sess.get_inputs()[0].name
out_name = sess.get_outputs()[0].name
print(f"[INFO] ONNX loaded with providers={providers}")
print(f"[INFO] inputs={in_name}, outputs={out_name}")

# MediaPipe Hands
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=MAX_NUM_HANDS,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)

# ì•ˆì •í™”/ì¿¨ë‹¤ìš´ ìƒíƒœ
recent = deque(maxlen=STABLE_FRAMES)
last_confirmed = None
last_sent_time = 0.0


# ì¹´ë©”ë¼ ì—´ê¸°
if CAMERA_INDEX is None:
    cap = select_camera(max_index=4)  # í•„ìš”í•˜ë©´ ìµœëŒ€ ì¸ë±ìŠ¤ ì¡°ì •
else:
    cap = open_camera(CAMERA_INDEX)

if not cap.isOpened():
    raise RuntimeError("ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

fps_t0 = time.time()
fps_cnt = 0
fps_val = 0.0

print("[INFO] ì‹œìž‘: 'q'ë¡œ ì¢…ë£Œ")
while True:
    ok, frame = cap.read()
    if not ok:
        print("[WARN] í”„ë ˆìž„ ì½ê¸° ì‹¤íŒ¨")
        break

    h, w = frame.shape[:2]
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    res = hands.process(rgb)

    roi = None
    roi_box = None
    # hand_present = False

    if res.multi_hand_landmarks:
        # ëª¨ë“  ëžœë“œë§ˆí¬ ì¢Œí‘œë¥¼ ì´ìš©í•´ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
        lm = res.multi_hand_landmarks[0]  # ì²« ë²ˆì§¸ ì†ë§Œ
        xs = [int(pt.x * w) for pt in lm.landmark]
        ys = [int(pt.y * h) for pt in lm.landmark]
        x1, x2 = min(xs), max(xs)
        y1, y2 = min(ys), max(ys)

        # pad + ì •ì‚¬ê° crop
        roi, roi_box = crop_square_with_pad(frame, x1, y1, x2, y2, PAD_PX)
        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)

    # ROI ì—†ìœ¼ë©´ ì „ì²´ í”„ë ˆìž„ì—ì„œ ì¤‘ì•™ ì •ì‚¬ê° í¬ë¡­ (fallback)
    if roi is None:
        side = min(h, w)
        sx1 = (w - side) // 2
        sy1 = (h - side) // 2
        roi = frame[sy1:sy1 + side, sx1:sx1 + side]
        roi_box = (sx1, sy1, sx1 + side, sy1 + side)
        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)

    # ì „ì²˜ë¦¬
    inp = cv2.resize(roi, INPUT_SIZE, interpolation=cv2.INTER_LINEAR)
    inp = inp.astype(np.float32) / 255.0          # [0, 1]
    inp = (inp - 0.5) / 0.5                       # [-1, 1]  == Normalize(0.5,0.5)
    inp = np.transpose(inp, (2, 0, 1))[None, ...] # (1, 3, H, W)


    # ì¶”ë¡ 
    probs = sess.run([out_name], {in_name: inp})[0].squeeze()  # (C,)
    if probs.ndim == 0:
        probs = np.array([1.0], dtype=np.float32)
    if probs.ndim == 1 and probs.shape[0] == len(labels):
        pred_prob = softmax(probs)
    else:
        # ì´ë¯¸ softmax ìƒíƒœì¼ ìˆ˜ë„ ìžˆìœ¼ë‹ˆ normalize
        x = probs.astype(np.float32)
        pred_prob = x / max(1e-9, x.sum())

    pred_idx = int(np.argmax(pred_prob))
    pred_label = labels[pred_idx]
    pred_conf = float(pred_prob[pred_idx])

    # ì•ˆì •í™” ë²„í¼ ì—…ë°ì´íŠ¸
    recent.append(pred_label)
    confirmed = None
    if len(recent) == STABLE_FRAMES and all(x == recent[0] for x in recent) and pred_conf >= CONF_THRESH:
        confirmed = recent[0]

    # í‚¤ ìž…ë ¥ (ì¿¨ë‹¤ìš´)
    now = time.time()
    if (
        confirmed
        # and hand_present
        and confirmed != last_confirmed and (now - last_sent_time) >= COOLDOWN_SEC):
        key = LABEL2KEY.get(confirmed)
        if key:
            print(f"[ACT] {confirmed} ({pred_conf:.2f}) -> key='{key}'")
            send_key(key)
            last_sent_time = now
            last_confirmed = confirmed
        else:
            print(f"[INFO] ë§¤í•‘ ì—†ìŒ: '{confirmed}' (labels.txtì™€ LABEL2KEY í™•ì¸)")

    # ì‹œê°í™”
    if DRAW_VIS and roi_box is not None:
        x1, y1, x2, y2 = roi_box
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        txt = f"{pred_label}:{pred_conf:.2f}"
        if confirmed:
            txt = f"[OK]{txt}"
        cv2.putText(frame, txt, (x1, max(20, y1 - 8)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                    (0, 255, 0) if confirmed else (0, 200, 255), 2)

    # FPS
    fps_cnt += 1
    if time.time() - fps_t0 >= 1.0:
        fps_val = fps_cnt / (time.time() - fps_t0)
        fps_cnt = 0
        fps_t0 = time.time()
    cv2.putText(frame, f"FPS: {fps_val:.1f}", (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

    cv2.imshow("ECA Gesture Presenter (Hand ROI)", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
print("[INFO] ì¢…ë£Œ")
